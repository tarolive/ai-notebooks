{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalando libs"
      ],
      "metadata": {
        "id": "Nnzrr6gojhxu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CzJMX9YL9t1f",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tensorflow tensorflow_hub keras_tuner pandas matplotlib==3.1.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importanto libs"
      ],
      "metadata": {
        "id": "i8pwVFPOkLeq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CQUkmEI-9t1g"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import keras_tuner as kt\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando dataset"
      ],
      "metadata": {
        "id": "MYSXr6pIkVKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sLCN9dLH9t1h"
      },
      "outputs": [],
      "source": [
        "dataset_url = 'https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data'\n",
        "dataset_columns = ['id', 'features', 'labels']\n",
        "dataset_offset = 1\n",
        "\n",
        "def read_dataset(dataset_name):\n",
        "  return pd.read_csv(dataset_url + dataset_name, names = dataset_columns, skiprows = lambda index : index < dataset_offset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando os datasets de treinamento, teste e validação"
      ],
      "metadata": {
        "id": "2uTp-RkElpSV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6WUwq429t1i"
      },
      "outputs": [],
      "source": [
        "dataset_train = read_dataset('/Constraint_Train.csv')\n",
        "dataset_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmMGlRfb9t1j"
      },
      "outputs": [],
      "source": [
        "dataset_test = read_dataset('/english_test_with_labels.csv')\n",
        "dataset_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_TlW3cW9t1k"
      },
      "outputs": [],
      "source": [
        "dataset_val = read_dataset('/Constraint_Val.csv')\n",
        "dataset_val.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Funções Auxiliares para utilizar label na classificação"
      ],
      "metadata": {
        "id": "6t2hcbmTl8MT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JeiQ2Ol_9t1k"
      },
      "outputs": [],
      "source": [
        "def transform(label):\n",
        "    return 1 if label == 'fake' else 0\n",
        "\n",
        "def inverse_transform(value):\n",
        "    return 'fake' if value >= 0.5 else 'real'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessamento"
      ],
      "metadata": {
        "id": "5vzNgUbNmXnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdjUWOIM9t1l"
      },
      "outputs": [],
      "source": [
        "dataset_train.pop('id')\n",
        "dataset_test.pop('id')\n",
        "dataset_val.pop('id')\n",
        "\n",
        "dataset_train['labels'] = [transform(label) for label in dataset_train['labels']]\n",
        "dataset_test['labels'] = [transform(label) for label in dataset_test['labels']]\n",
        "dataset_val['labels'] = [transform(label) for label in dataset_val['labels']]\n",
        "\n",
        "print(dataset_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando modelo pré-treinado como camada de incorporação de texto"
      ],
      "metadata": {
        "id": "LYzv3sRCmhix"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UN7rgP7u9t1m"
      },
      "outputs": [],
      "source": [
        "embedding_layer_name = 'https://tfhub.dev/google/nnlm-en-dim128/2'\n",
        "embedding_layer = hub.KerasLayer(embedding_layer_name, input_shape = [], dtype = tf.string, trainable = False)\n",
        "\n",
        "embedding_layer(dataset_train['features'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo função para construir modelo"
      ],
      "metadata": {
        "id": "VWh3UCnpo-qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(embedding_layer)\n",
        "\n",
        "    hp_units = hp.Int('units', min_value = 8, max_value = 64, step = 8)\n",
        "    model.add(tf.keras.layers.Dense(units = hp_units, activation = 'relu'))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics = ['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "rz9VlLvNo9lk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo tuner"
      ],
      "metadata": {
        "id": "L68slJWTrQ-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective = 'val_accuracy',\n",
        "    max_epochs = 50,\n",
        "    factor = 3\n",
        ")"
      ],
      "metadata": {
        "id": "vE1AYYQvrOHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo função para parar processamento caso validation loss não sofra redução (saturação da aprendizagem)"
      ],
      "metadata": {
        "id": "n1oj32UJrqLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 5)"
      ],
      "metadata": {
        "id": "ks8bdymcrz3t"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buscando melhores valores de parâmetros"
      ],
      "metadata": {
        "id": "MR5kBPz5r4hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    dataset_train['features'],\n",
        "    dataset_train['labels'],\n",
        "    epochs = 50,\n",
        "    validation_data = (dataset_val['features'], dataset_val['labels']),\n",
        "    batch_size = 512,\n",
        "    validation_batch_size = 512,\n",
        "    verbose = 1,\n",
        "    callbacks = [ stop_early ]\n",
        ")\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]"
      ],
      "metadata": {
        "id": "Em81HKEjsK-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinando o modelo utilizando os melhores parâmetros"
      ],
      "metadata": {
        "id": "DG8K_xjewF2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    dataset_train['features'],\n",
        "    dataset_train['labels'],\n",
        "    batch_size = 512,\n",
        "    validation_data = (dataset_val['features'], dataset_val['labels']),\n",
        "    validation_batch_size = 512,\n",
        "    epochs = 30,\n",
        "    verbose = 1\n",
        ")"
      ],
      "metadata": {
        "id": "nNXUhQ33wGIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotando resultados dos treinamentos"
      ],
      "metadata": {
        "id": "A3Mydb2koRJ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9adZWv19t1o"
      },
      "outputs": [],
      "source": [
        "history_dict = history.history\n",
        "\n",
        "accuracy = history_dict['accuracy']\n",
        "val_accuracy = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEB0hPCc9t1o"
      },
      "outputs": [],
      "source": [
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
        "plt.legend(loc = 'lower right')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizando o modelo no dataset de teste"
      ],
      "metadata": {
        "id": "lVnqdEsIqOEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8foR6is9t1p"
      },
      "outputs": [],
      "source": [
        "model.evaluate(\n",
        "    dataset_test['features'],\n",
        "    dataset_test['labels'],\n",
        "    verbose = 1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizando previsões em sentenças"
      ],
      "metadata": {
        "id": "lrbMvevDqVBh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bLUtVgjM9t1p"
      },
      "outputs": [],
      "source": [
        "def predict(inputs):\n",
        "\n",
        "    outputs = model.predict(inputs)\n",
        "\n",
        "    for i, o in zip(inputs, outputs):\n",
        "        print(f'Input: {i}')\n",
        "        print(f'Output Score: {o[0]} | Output Label: {inverse_transform(o[0])}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ryqyiFMz9t1q"
      },
      "outputs": [],
      "source": [
        "inputs = [\n",
        "    'The Chinese government announced that \"garlic is a preventative food for the the novel coronavirus.\"',\n",
        "    'Hydroxychloroquine is the cure for coronavirus.',\n",
        "    'Mass disinfection of people using a chemical solution will eradicate COVID-19.',\n",
        "    'The coronavirus was engineered by scientists in a lab.',\n",
        "    'Practice social distancing to slow the spread of covid.',\n",
        "    'Wear a mask in public to help prevent the virus.', # most sentences in the dataset using the word \"mask\" is fake\n",
        "    'Fever and difficulty breathing are symptoms of coronavirus.'\n",
        "]\n",
        "\n",
        "predict(inputs)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "text_classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}