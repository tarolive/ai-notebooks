{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzJMX9YL9t1f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade tensorflow tensorflow_hub pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQUkmEI-9t1g"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLCN9dLH9t1h"
   },
   "outputs": [],
   "source": [
    "dataset_url = 'https://raw.githubusercontent.com/diptamath/covid_fake_news/main/data'\n",
    "dataset_columns = ['id', 'features', 'labels']\n",
    "dataset_offset = 1\n",
    "\n",
    "def read_dataset(dataset_name):\n",
    "  return pd.read_csv(dataset_url + dataset_name, names = dataset_columns, skiprows = lambda index : index < dataset_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6WUwq429t1i"
   },
   "outputs": [],
   "source": [
    "dataset_train = read_dataset('/Constraint_Train.csv')\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zmMGlRfb9t1j"
   },
   "outputs": [],
   "source": [
    "dataset_test = read_dataset('/english_test_with_labels.csv')\n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_TlW3cW9t1k"
   },
   "outputs": [],
   "source": [
    "dataset_val = read_dataset('/Constraint_Val.csv')\n",
    "dataset_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JeiQ2Ol_9t1k"
   },
   "outputs": [],
   "source": [
    "def transform(label):\n",
    "    result = 1 if label == 'fake' else 0\n",
    "    return result\n",
    "\n",
    "def inverse_transform(value):\n",
    "    result = 'fake' if value >= 0.5 else 'real'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdjUWOIM9t1l"
   },
   "outputs": [],
   "source": [
    "dataset_train.pop('id')\n",
    "dataset_test.pop('id')\n",
    "dataset_val.pop('id')\n",
    "\n",
    "dataset_train['labels'] = [transform(label) for label in dataset_train['labels']]\n",
    "dataset_test['labels'] = [transform(label) for label in dataset_test['labels']]\n",
    "dataset_val['labels'] = [transform(label) for label in dataset_val['labels']]\n",
    "\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UN7rgP7u9t1m"
   },
   "outputs": [],
   "source": [
    "embedding_layer_name = 'https://tfhub.dev/google/nnlm-en-dim128/2'\n",
    "embedding_layer = hub.KerasLayer(embedding_layer_name, input_shape = [], dtype = tf.string, trainable = False)\n",
    "\n",
    "embedding_layer(dataset_train['features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ovc7Z129t1m"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    embedding_layer,\n",
    "    tf.keras.layers.Dense(16, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZVCCwySp9t1n"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(), loss = tf.keras.losses.BinaryCrossentropy(from_logits = False), metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1uZDpKL9t1n"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    dataset_train['features'],\n",
    "    dataset_train['labels'],\n",
    "    batch_size = 512,\n",
    "    validation_data = (dataset_val['features'], dataset_val['labels']),\n",
    "    validation_batch_size = 512,\n",
    "    epochs = 30,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G9adZWv19t1o"
   },
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(accuracy) + 1)\n",
    "\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(epochs, loss, 'bo', label = 'Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEB0hPCc9t1o"
   },
   "outputs": [],
   "source": [
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\n",
    "plt.legend(loc = 'lower right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A8foR6is9t1p"
   },
   "outputs": [],
   "source": [
    "model.evaluate(\n",
    "    dataset_test['features'],\n",
    "    dataset_test['labels'],\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLUtVgjM9t1p"
   },
   "outputs": [],
   "source": [
    "def predict(inputs):\n",
    "\n",
    "    outputs = model.predict(inputs)\n",
    "\n",
    "    for i, o in zip(inputs, outputs):\n",
    "        print(f'Input: {i}')\n",
    "        print(f'Output Score: {o[0]} | Output Label: {inverse_transform(o[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryqyiFMz9t1q"
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    'The Chinese government announced that \"garlic is a preventative food for the the novel coronavirus.\"',\n",
    "    'Hydroxychloroquine is the cure for coronavirus.',\n",
    "    'Mass disinfection of people using a chemical solution will eradicate COVID-19.',\n",
    "    'The coronavirus was engineered by scientists in a lab.',\n",
    "    'Practice social distancing to slow the spread of covid.',\n",
    "    'Wear a mask in public to help prevent the virus.', # most sentences in the dataset using the word \"mask\" is fake\n",
    "    'Fever and difficulty breathing are symptoms of coronavirus.'\n",
    "]\n",
    "\n",
    "predict(inputs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "text_classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
